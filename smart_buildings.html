<!DOCTYPE html>
<html>
<head>
  <link rel="stylesheet" href="style.css" media="">
  <meta name="viewport" type="text/css" content="width=device-width">
  <meta charset="utf-8">
  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
  <title>My Laboratory - People</title>
</head>

<body>
  <nav class="navbar navbar-expand-sm">
    <img src="https://st0.xo.gr/files/1/Backoffice/customer_photos/MY_LAB_DIAGNOSTIKA_ERGASTIRIA_VIOPATHOLOGIAS_2180afd7d9a64e6ba5e84ef4de64d50e.jpg"width="350" height="200">
    <h3 id="name">My Labratory</h3>
      <!-- <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#collapsibleNavbar">
        <span class="navbar-toggler-icon"></span>
      </button> -->
      <div class="collapse navbar-collapse" id="collapsibleNavbar">
        <ul class="navbar-nav">
          <!-- Style margins for spacings -->
          <li class="nav-item">
            <a class="nav-link" href="index.html"><span>Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="people.html"><span>People</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="interests.html"><span>Interest</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="curr_projects.html"><span>Projects</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="publications.html"><span>Publications</a>
          </li>
        </ul>
      </div>
  </nav>

  <div class="container-fluid">
    <div class="container-fluid" id="proj">
      <h2><a href="https://www.researchgate.net/publication/282379510_Smart_buildings_and_the_human-machine_cloud">
      Smart Buildings</a></h2>
    </div>

    <div class="container-fluid" id="descript">
      <p><b>About:</b> <br>The Human-Robot Cloud has previously been introduced
        as a framework for the creation of distributed, on-demand, reconfigurable
         human-machine cognitive systems. These systems are made up of sensing,
         processing, and actuation components that are not limited to a specific
         type of application and potentially can be extended to multiple domains
         and may cover spatially smaller or larger areas. In this paper, we revisit
         the Human-Robot Cloud architecture and present its pilot deployment on
         the campus of NCSR Demokritos, a research institution in Greece. In particular,
          our concrete deployment aims to be demonstrated in three specific application
          scenarios; namely, Human-Aware Smart Buildings with Energy Optimization,
          Security and Surveillance, and Smart Tour Guide System. In this paper,
          we present in detail an example implementation of the Smart Buildings
          scenario: a real-world application with immediate benefits in energy
          optimization and energy savings. Environmentally sensitive issues, such
          as the ground-up development of energy efficient buildings or reducing
          the environmental impact of the existing infrastructure, has received
          much attention in the past. However, the traditionally offered solutions
          are central, non-transferable to other infrastructure, non-scalable and
          suffer from single points of failure. On the contrary, in this work, which
          is based on a specialization of the generic Human-Robot Cloud architecture,
          we attempt to move beyond the industrially available solutions to meet the
          requirements for scalable, reconfigurable and redistributable sensory,
          processing, and actuation units within buildings. A set of cameras, laser
          range finders, and other sensors, together with a number of processing
          and actuation elements, including face detection, expression recognition,
          and people trackers, are transformed to a prototypical reconfigurable
          distributed extended cognitive system, which can support multiple applications
          in the future.</p>
    </div>

    <div class="container-fluid" id="figures">
      <p><b>Figures:</b></p>
      <div class="grid-container">
        <div class="grid-item">
          <img src="https://www.researchgate.net/profile/Nikolaos_Mavridis2/publication/282379510/figure/fig1/AS:365588112265216@1464174406018/Typical-classes-of-Sensing-Processing-and-Actuation-components-that-can-be-reconfigured.png"
          width="300px" height="350">
          <p>Typical classes of Sensing, Processing, and Actuation components
            that can be reconfigured to support all three application scenarios
            or other complex domains.</p>
        </div>

        <div class="grid-item">
          <img src="https://www.researchgate.net/profile/Nikolaos_Mavridis2/publication/282379510/figure/fig2/AS:365588112265217@1464174406046/Single-frame-of-the-people-counting-processing-unit-in-the-main-room-that-our-system-was.png"
           width="300px" height="350">
            <p>Single frame of the people counting processing unit in the main
              room that our system was deployed.</p>
        </div>
      </div>
    </div>


  </div>

</body>
</html>
